{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_in_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1462</td>\n",
       "      <td>No</td>\n",
       "      <td>243.39</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Haze</td>\n",
       "      <td>haze</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037</td>\n",
       "      <td>No</td>\n",
       "      <td>243.62</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Haze</td>\n",
       "      <td>haze</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>No</td>\n",
       "      <td>244.22</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354</td>\n",
       "      <td>No</td>\n",
       "      <td>244.82</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Party Cloudy</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>417</td>\n",
       "      <td>No</td>\n",
       "      <td>244.82</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Party Cloudy</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   traffic_volume holiday    temp  rain_1h  snow_1h    clouds_all  \\\n",
       "0            1462      No  243.39  No rain  No snow         Clear   \n",
       "1            1037      No  243.62  No rain  No snow         Clear   \n",
       "2             800      No  244.22  No rain  No snow         Clear   \n",
       "3             354      No  244.82  No rain  No snow  Party Cloudy   \n",
       "4             417      No  244.82  No rain  No snow  Party Cloudy   \n",
       "\n",
       "  weather_main weather_description  year  month  day  hour  day_in_week  \\\n",
       "0         Haze                haze  2016     12   18     8            6   \n",
       "1         Haze                haze  2016     12   18     7            6   \n",
       "2        Clear        sky is clear  2016     12   18     6            6   \n",
       "3       Clouds          few clouds  2013      2    2     3            5   \n",
       "4       Clouds          few clouds  2013      2    2     4            5   \n",
       "\n",
       "   is_weekend  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = '../data/processed_data.csv'\n",
    "data = pd.read_csv(path)\n",
    "data = data.sort_values(by=[\"temp\", \"rain_1h\", \"snow_1h\", 'clouds_all'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48193 entries, 0 to 48192\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   traffic_volume       48193 non-null  int64  \n",
      " 1   holiday              48193 non-null  object \n",
      " 2   temp                 48193 non-null  float64\n",
      " 3   rain_1h              48193 non-null  object \n",
      " 4   snow_1h              48193 non-null  object \n",
      " 5   clouds_all           48193 non-null  object \n",
      " 6   weather_main         48193 non-null  object \n",
      " 7   weather_description  48193 non-null  object \n",
      " 8   year                 48193 non-null  int64  \n",
      " 9   month                48193 non-null  int64  \n",
      " 10  day                  48193 non-null  int64  \n",
      " 11  hour                 48193 non-null  int64  \n",
      " 12  day_in_week          48193 non-null  int64  \n",
      " 13  is_weekend           48193 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(6)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "  \"\"\"\n",
    "    split data based on snow_1h and rain_1h columns.\n",
    "    \n",
    "    Steps:\n",
    "    1. 90% of rows where 'snow_1h' == 'Have snow' go to train, 10% to test.\n",
    "    2. from the remaining training data, 90% of rows where 'rain_1h' == 'Have rain' stay in train, 10% move to test.\n",
    "    3. split continue in train dataset\n",
    "    \n",
    "  \"\"\"\n",
    "  # define snow for handle imbalance\n",
    "  have_snow = data[data['snow_1h'] == 'Have snow']\n",
    "  no_snow = data[data['snow_1h'] != 'Have snow']\n",
    "  \n",
    "  # split by snow\n",
    "  snow_train = have_snow.sample(frac=0.9, random_state=42) \n",
    "  snow_test = have_snow.drop(snow_train.index)\n",
    "  \n",
    "  train_data = pd.concat([no_snow, snow_train])\n",
    "  test_data = snow_test\n",
    "  \n",
    "  # define value in rain for handle imbalance\n",
    "  have_rain = data[data['rain_1h'] == 'Have rain']\n",
    "  no_rain = data[data['rain_1h'] == 'No rain']\n",
    "  \n",
    "  # continue slit with rain\n",
    "  rain_train = have_rain.sample(frac=0.9, random_state=42) \n",
    "  rain_test = have_rain.drop(rain_train.index)  \n",
    "  \n",
    "  # train & test after split by columns\n",
    "  train_data = pd.concat([no_rain, rain_train])\n",
    "  test_data = pd.concat([test_data, rain_test])\n",
    "  \n",
    "  # Split in train set to get enough value for testing\n",
    "  final_train = train_data.sample(frac=0.8, random_state=42)  \n",
    "  validation = train_data.drop(final_train.index)  \n",
    "  test_data = pd.concat([test_data, validation])\n",
    "\n",
    "  return final_train, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset length:  38277\n",
      "test data length:  9922\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_dataset(data)\n",
    "print(f\"train dataset length: \", len(train_data))\n",
    "print(f\"test data length: \", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoding(df):\n",
    "  # include only category columns\n",
    "  category_column = df.select_dtypes(include=['object']).columns.tolist()\n",
    "  \n",
    "  encoded_df = df.copy()\n",
    "  for col in category_column:\n",
    "    encoded_df[col] = encoded_df[col].astype(str)\n",
    "    \n",
    "    label_encode = LabelEncoder()\n",
    "    encoded_df[col] = label_encode.fit_transform(encoded_df[col])\n",
    "\n",
    "  return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = label_encoding(train_data)\n",
    "test_data = label_encoding(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def gradient_boosting_train(train_data, target_column, feature_columns, n_splits=10, scoring='neg_root_mean_squared_error'):\n",
    "    param_grid = {\n",
    "      'learning_rate': [0.05, 0.01, 0.1],\n",
    "      'min_samples_split':[6, 10, 15],\n",
    "      'max_depth': [2, 3, 4],\n",
    "      'min_samples_leaf': [5, 10, 20],\n",
    "      'subsample': [0.6, 0.8, 1.0],\n",
    "      'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    X_train = train_data[feature_columns]\n",
    "    y_train = train_data[target_column]\n",
    "    gbr = GradientBoostingRegressor(random_state=42, n_iter_no_change=10, validation_fraction=0.2)\n",
    "    tscv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # print log data for debug\n",
    "    def print_progress(cv_results, n_iter):\n",
    "        print(f\"Iteration {n_iter}/{len(cv_results['mean_test_score'])}:\")\n",
    "        print(f\"Params: {cv_results['params'][n_iter - 1]}\")\n",
    "        print(f\"Mean Test Score: {cv_results['mean_test_score'][n_iter - 1]}\")\n",
    "        print(f\"Std Test Score: {cv_results['std_test_score'][n_iter - 1]}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=tscv, scoring=scoring, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Log parameter results during fitting\n",
    "    for i in range(len(grid_search.cv_results_['params'])):\n",
    "        print_progress(grid_search.cv_results_, i + 1)\n",
    "    \n",
    "    # get best params + estimators\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # calculate r2\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    return best_model, best_params, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(model, test_data, target_column, feature_columns):\n",
    "    X_test = test_data[feature_columns]\n",
    "    y_test = test_data[target_column]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    return rmse, f\"The RMSE of the {model} is {rmse}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model dumping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def save_file(scaler, filename):\n",
    "    joblib.dump(scaler, filename)\n",
    "    return f\"Saving {filename} successfully executed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holiday',\n",
       " 'temp',\n",
       " 'rain_1h',\n",
       " 'snow_1h',\n",
       " 'clouds_all',\n",
       " 'weather_main',\n",
       " 'weather_description',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'day_in_week',\n",
       " 'is_weekend']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in train_data.columns if col != \"traffic_volume\"]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "\n",
      " Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      " R2 on Train-set: 0.9858321072918674\n",
      "\n",
      " Root Mean Squared Error (RMSE) on Test Set: (398.9927449378183, 'The RMSE of the GradientBoostingRegressor(learning_rate=0.2, max_depth=6, min_samples_leaf=7,\\n                          min_samples_split=3, n_estimators=300,\\n                          random_state=42, subsample=0.8) is 398.9927449378183')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params, r2_train = gradient_boosting_train(train_data, target_column=\"traffic_volume\", feature_columns=feature_columns)\n",
    "# evaluation\n",
    "rmse, evaluation_message = evaluate_model(best_model, test_data, target_column=\"traffic_volume\", feature_columns=feature_columns)\n",
    "\n",
    "print(f\"\\n Best Hyperparameters: {best_params}\"),\n",
    "print(f\"\\n R2 on Train-set: {r2_train}\"),\n",
    "print(f\"\\n Root Mean Squared Error (RMSE) on Test Set: {rmse}\")\n",
    "print(evaluation_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saving ./saved_feature/gbr.joblib successfully executed'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './saved_feature/gbr.joblib'\n",
    "save_file(best_model, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
