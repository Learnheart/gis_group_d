{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1462</td>\n",
       "      <td>No</td>\n",
       "      <td>243.39</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Haze</td>\n",
       "      <td>haze</td>\n",
       "      <td>08:00</td>\n",
       "      <td>18-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037</td>\n",
       "      <td>No</td>\n",
       "      <td>243.62</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Haze</td>\n",
       "      <td>haze</td>\n",
       "      <td>07:00</td>\n",
       "      <td>18-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>No</td>\n",
       "      <td>244.22</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>06:00</td>\n",
       "      <td>18-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354</td>\n",
       "      <td>No</td>\n",
       "      <td>244.82</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Party Cloudy</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>03:00</td>\n",
       "      <td>02-02-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>417</td>\n",
       "      <td>No</td>\n",
       "      <td>244.82</td>\n",
       "      <td>No rain</td>\n",
       "      <td>No snow</td>\n",
       "      <td>Party Cloudy</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>04:00</td>\n",
       "      <td>02-02-2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   traffic_volume holiday    temp  rain_1h  snow_1h    clouds_all  \\\n",
       "0            1462      No  243.39  No rain  No snow         Clear   \n",
       "1            1037      No  243.62  No rain  No snow         Clear   \n",
       "2             800      No  244.22  No rain  No snow         Clear   \n",
       "3             354      No  244.82  No rain  No snow  Party Cloudy   \n",
       "4             417      No  244.82  No rain  No snow  Party Cloudy   \n",
       "\n",
       "  weather_main weather_description   time        date  \n",
       "0         Haze                haze  08:00  18-12-2016  \n",
       "1         Haze                haze  07:00  18-12-2016  \n",
       "2        Clear        sky is clear  06:00  18-12-2016  \n",
       "3       Clouds          few clouds  03:00  02-02-2013  \n",
       "4       Clouds          few clouds  04:00  02-02-2013  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = '../data/processed_data.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_volume         6\n",
      "holiday                6\n",
      "temp                   6\n",
      "rain_1h                6\n",
      "snow_1h                6\n",
      "clouds_all             6\n",
      "weather_main           6\n",
      "weather_description    6\n",
      "time                   6\n",
      "date                   6\n",
      "dtype: int64\n",
      "traffic_volume         57\n",
      "holiday                57\n",
      "temp                   57\n",
      "rain_1h                57\n",
      "snow_1h                57\n",
      "clouds_all             57\n",
      "weather_main           57\n",
      "weather_description    57\n",
      "time                   57\n",
      "date                   57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "have_snow = data[data['snow_1h'] == 'Have snow']\n",
    "no_snow = data[data['snow_1h'] != 'Have snow']\n",
    "\n",
    "snow_train = have_snow.sample(frac=0.9, random_state=42) \n",
    "snow_test = have_snow.drop(snow_train.index)\n",
    "\n",
    "print(snow_test.count())\n",
    "print(snow_train.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "  \"\"\"\n",
    "    split data based on snow_1h and rain_1h columns.\n",
    "    \n",
    "    Steps:\n",
    "    1. 90% of rows where 'snow_1h' == 'Have snow' go to train, 10% to test.\n",
    "    2. from the remaining training data, 90% of rows where 'rain_1h' == 'Have rain' stay in train, 10% move to test.\n",
    "    3. split continue in train dataset\n",
    "    \n",
    "  \"\"\"\n",
    "  # define snow for handle imbalance\n",
    "  have_snow = data[data['snow_1h'] == 'Have snow']\n",
    "  no_snow = data[data['snow_1h'] != 'Have snow']\n",
    "  \n",
    "  # split by snow\n",
    "  snow_train = have_snow.sample(frac=0.9, random_state=42) \n",
    "  snow_test = have_snow.drop(snow_train.index)\n",
    "  \n",
    "  train_data = pd.concat([no_snow, snow_train])\n",
    "  test_data = snow_test\n",
    "  \n",
    "  # define value in rain for handle imbalance\n",
    "  have_rain = data[data['rain_1h'] == 'Have rain']\n",
    "  no_rain = data[data['rain_1h'] == 'No rain']\n",
    "  \n",
    "  # continue slit with rain\n",
    "  rain_train = have_rain.sample(frac=0.9, random_state=42) \n",
    "  rain_test = have_rain.drop(rain_train.index)  \n",
    "  \n",
    "  # train & test after split by columns\n",
    "  train_data = pd.concat([no_rain, rain_train])\n",
    "  test_data = pd.concat([test_data, rain_test])\n",
    "  \n",
    "  # Split in train set to get enough value for testing\n",
    "  final_train = train_data.sample(frac=0.8, random_state=42)  \n",
    "  validation = train_data.drop(final_train.index)  \n",
    "  test_data = pd.concat([test_data, validation])\n",
    "\n",
    "  return final_train, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset length:  38277\n",
      "test data length:  9922\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_dataset(data)\n",
    "print(f\"train dataset length: \", len(train_data))\n",
    "print(f\"test data length: \", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def gradient_boosting_train(train_data, target_column, feature_columns, n_splits=5, scoring='neg_root_mean_squared_error'):\n",
    "    param_grid = {\n",
    "      'learning_rate': [0.05, 0.2, 0.1],\n",
    "      'min_samples_split':[3, 5, 6],\n",
    "      'max_depth': [4, 5, 6],\n",
    "      'min_samples_leaf': [1, 3, 5, 7],\n",
    "      'subsample': [0.6, 0.8, 1.0],\n",
    "      'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    X_train = train_data[feature_columns]\n",
    "    y_train = train_data[target_column]\n",
    "    gbr = GradientBoostingRegressor(random_state=42)\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=tscv, scoring=scoring, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # get best params + estimators\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # calculate r2\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    return best_model, best_params, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(model, test_data, target_column, feature_columns):\n",
    "    X_test = test_data[feature_columns]\n",
    "    y_test = test_data[target_column]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    return rmse, f\"The RMSE of the {model} is {rmse}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model dumping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def save_file(scaler, filename):\n",
    "    joblib.dump(scaler, filename)\n",
    "    return f\"Saving {filename} successfully executed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in train_data.columns if col != \"traffic_volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 4860 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4860 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 659, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 997, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'No'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model, best_params, r2_train \u001b[38;5;241m=\u001b[39m gradient_boosting_train(train_data, target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraffic_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_columns\u001b[38;5;241m=\u001b[39mfeature_columns)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# evaluation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m rmse \u001b[38;5;241m=\u001b[39m evaluate_model(best_model, test_data, target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraffic_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_columns\u001b[38;5;241m=\u001b[39mfeature_columns)\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mgradient_boosting_train\u001b[1;34m(train_data, target_column, feature_columns, n_splits, scoring)\u001b[0m\n\u001b[0;32m     17\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39mn_splits)\n\u001b[0;32m     19\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mgbr, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mtscv, scoring\u001b[38;5;241m=\u001b[39mscoring, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# get best params + estimators\u001b[39;00m\n\u001b[0;32m     23\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32md:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32md:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 4860 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4860 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 659, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1263, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 997, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Probability\\envs\\deployment\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'No'\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params, r2_train = gradient_boosting_train(train_data, target_column=\"traffic_volume\", feature_columns=feature_columns)\n",
    "# evaluation\n",
    "rmse = evaluate_model(best_model, test_data, target_column=\"traffic_volume\", feature_columns=feature_columns)\n",
    "\n",
    "print(f\"\\n Best Hyperparameters: {best_params}\"),\n",
    "print(f\"\\n R2 on Train-set: {r2_train}\"),\n",
    "print(f\"\\n Root Mean Squared Error (RMSE) on Test Set: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
